# vietnamese-voice-forge
## üìñ Overview
This project focuses on **Vietnamese style paraphrasing** as an entry point into natural language processing (NLP). 
Specifically, we excecute two tasks: paraphrasing modern Vietnamese sentence to ancient style (c·ªï trang) Vietnamese sentence, and paraphrasing modern Vietnamese sentence to Quang Binh Dialect. 

*Note: the API is currently stopped, hence the UI will return error if you try to use. You can use the model that we upload and run it yourself*

Below are two examples of paraphrasing: 
- **Modern sentence**: "Anh ·∫•y lu√¥n c·ªë g·∫Øng h·∫øt s·ª©c ƒë·ªÉ b·∫£o v·ªá gia ƒë√¨nh m√¨nh." ->  **Ancient Vietnamese Sentence**: "Ch√†ng d·ªëc h·∫øt t√¢m can, nguy·ªán l·∫•y th√¢n n√†y che ch·ªü gia quy·∫øn."
- **Modern Sentence**: "Xin ch√†o b·∫°n, v√¨ sao b·∫°n xinh ƒë·∫πp ƒë·∫øn v·∫≠y" -> **QB Dialect**: "Ch√†o mi, rƒÉng mi ƒë·∫πp c·∫•y r·ª©a h√®"
We compare two main approaches:

1. **Cost-efficient model fine-tuning**
2. **RAG pipelines leveraging DeepSeek V3**

In total, we trained and deployed 4 models. 2 finetuned models and 2 others model using RAG pipelines, Details will be specified below.

DeepSeek V3 was chosen for its **robustness in Vietnamese** and **cost-effectiveness** compared to other popular models such as OpenAI GPT-4o and Gemini.  

üëâ The entire project was conducted under a budget of **$30**, showcasing the viability of low-cost NLP research for low-resource languages like Vietnamese.

--- 

## ‚öôÔ∏è Methodology

### 1. Training & Data Collection
- **Fine-tuning models**:  
  - `Deepseek-r1-distill-qwen-1.5b-bnb-4bit`  
  - `DeepSeek-R1-0528-Qwen3-8B-unsloth-bnb-4bit`  
  - Chosen for cost efficiency and effective fine-tuning capability.

 - **Fine-tuning methods**: Using Hugging Face Transformer library 

- **Dialect adaptation (Qu·∫£ng B√¨nh)**:  
  - Used DeepSeek V3 with a **rule file** to generate ~20,000 sentence pairs.  
  - We also tried OpenAI GPT-40 and found that DeepSeek V3 outperformed OpenAI GPT-4o in idiomatic accuracy (human-eval).

- **Classical style (C·ªï Trang)**:  
  - Collected ~40,000 sentences ([Dataset link](https://huggingface.co/datasets/triettheeducator/modern-to-ancient-vietnamese-paraphrased-dataset))
 from classical novels:  
    *H·ªìng L√¢u M·ªông, Tam Qu·ªëc Di·ªÖn Nghƒ©a, Li√™u Trai Ch√≠ D·ªã, Th·ªßy H·ª≠, T√¢y Du K√Ω*.  
  - Translated them into modern Vietnamese using GPT-4o Mini.  
  - Dataset is available on Hugging Face.

- **RAG pipeline**:  
  - Built using `RecursiveCharacterTextSplitter` from LangChain.  
  - Paired with DeepSeek V3 for semantic retrieval and paraphrasing.

---

### 2. Evaluation
- **Metrics**:  
  - **BERTScore** ‚Üí semantic similarity. F1 score to be more specific
  - **Self-BLEU** ‚Üí diversity of paraphrasing (coming soon) 

- **Test Dataset**:  
  - 1,000 Vietnamese sentences from [this dataset](https://huggingface.co/datasets/DiligentPenguinn/vietnamese-paraphrase-pairs-dataset)

- **Result**
+ QB Dialect finetuned: 0.669
+ Ancient Vietnamese fine-tuned: 0.773
+ Deepseek + Rag for QB Dialect: 0.914
+ Deepseek + Rag for Vietnamese ancient style paraphrasing: 0.551 (It seems that we need to update embedding model, so Bertscore can capture semantic similarity more correctly, as by human-evaluation, we see the paraphrased sentence is quite close to the original sentence, semantically. 

![Thi·∫øt k·∫ø ch∆∞a c√≥ t√™n](https://github.com/user-attachments/assets/58a71f5b-856e-4950-8ec2-fc94b7413f1b)


---

## üöÄ Deployment
- **Model hosting**: [VastAI](https://vast.ai/) (low-cost GPU inference)  
- **Backend**: [Supabase](https://supabase.com/)  
- **Frontend**: [Lovable](https://lovable.dev/)  

---

## Future Work

- Execute more NLP methods to increase paraphrasing quality
- Explore the dynamic impact of different languages such as Vietnamese and English to performance of small-size model (< 1B parameters)

## Acknowledgment
THis is our first project exploring NLP. There are so many rooms for improvement and many more things to learn. This is not by any mean the standard way for executing paraphrasing task. 

## üë• Authors

- **Minh Triet Nguyen**  
  Graduate, Marketing Management ‚Äì British University Vietnam  
  üìß Email: [Triet2one@gmail.com](mailto:Triet2one@gmail.com)

- **Duy Dang Hoang**  
  Junior, Computer Science ‚Äì National University of Singapore  
  üìß Email: [hoangduyqb2209@gmail.com](mailto:hoangduyqb2209@gmail.com)

---
